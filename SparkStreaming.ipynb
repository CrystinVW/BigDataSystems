{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-aling:center;color:Navy'>  Big Data Systems - Lab #6  </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='text-aling:center;color:RED'> Your name is Crystin Rodrick</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#3665af\">Stream Processing </span><span style=\"font-size:15px\">(Estimated time: 1 hour) </span>\n",
    "<hr>\n",
    "The objective of this lab is to introduce the use of Spark streaming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">Example 1 - Word Count </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple example of using pyspark streaming library. \n",
    "\n",
    "You have to run through the example, understand what the code is doing. \n",
    "Just follow the instructions and run cells to get a sense of how Spark Streaming works.\n",
    "By the end of the lab session, make sure you are submitting the outputs of this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "findspark.init('/home/crystin/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first parameter of SparkContext indicates that this application will be run on a single node (not a cluster).\n",
    "The second parameter is just a name given to this application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext('local[2]','NetworkWordCount') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we initialize the streamig context and set the batch interval to 5 seconds. It means that, each batch will contain the data (RDDs) for 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want the streaming context to read data from a socket. We need to use a port that is not already in use, like 9999. <br/>\n",
    "if you get the folloiwng terminal error 'port xxxx is already in use' change the port number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream('localhost',9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to receive every line of text from the given port and extract words from each line. <br>\n",
    "We use the flatMap functuion since each line may contain multiple words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = lines.flatMap(lambda line: line.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to map each word, to a key value pair, where the key is the word itself and the value is always 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs = words.map(lambda word:(word,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *reduceByKey* treats the first element of each pair as key and the second element as value!\n",
    "Then, it groups all values belonging to the same key together.\n",
    "Now, for couting each word, we simply need to add up all values for that word together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_counts = pairs.reduceByKey(lambda num1,num2:num1+num2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we present the count for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_counts.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to start the process. Before running the next cell, open a terminal and type: \n",
    "nc -lk 9999\n",
    "Now you can send messages to port 9999 using the netcat (nc) program.\n",
    "Go ahead and run the next cell; then go back to terminal and send some messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2018-04-12 12:44:40\n",
      "-------------------------------------------\n",
      "('this', 1)\n",
      "('is', 1)\n",
      "('a', 1)\n",
      "('mesage', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-04-12 12:44:45\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-04-12 12:44:50\n",
      "-------------------------------------------\n",
      "('this', 1)\n",
      "('is', 1)\n",
      "('new', 1)\n",
      "('a', 1)\n",
      "('message', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-04-12 12:44:55\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-04-12 12:45:00\n",
      "-------------------------------------------\n",
      "('ths', 1)\n",
      "('is', 1)\n",
      "('new', 1)\n",
      "('a', 1)\n",
      "('message', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-04-12 12:45:05\n",
      "-------------------------------------------\n",
      "('', 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are done, run the next cell to stop the streaming context. <br>\n",
    "Note that if you want to run the streaming context again, you need to restart the kernel. You may also need to change the port no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">Example 2 - Tweet analysis </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before Continuing\n",
    "\n",
    "Before we start with this part of the lab, we will need to run the python program *tweetread.py* that reads the tweets and streams those to a local port.\n",
    "\n",
    "On a text editor open the file *tweetread.py*. We need to configure the following parameters. You should obtain the value for each parameter from your tweeter configuration (review the guide).\n",
    "\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "# Set up your credentials\n",
    "# add your credentials between ''\n",
    "consumer_key=''\n",
    "consumer_secret=''\n",
    "access_token =''\n",
    "access_secret=''\n",
    "</pre>\n",
    "\n",
    "\n",
    "Also, you might need to change this port in case you receive a *'port xxxx is already in use'* error.\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "port = 5555\n",
    "</pre>\n",
    "\n",
    "\n",
    "**Open a new shell terminal** and execute the following commands.<br>\n",
    "*We assume you have your downloaded files for this assignment at **~/lab6**, if you are using another path, replace it below.*\n",
    "<pre style=\"background-color: #ebece4;padding: 10px;border-left: solid 4px orange;\">\n",
    "cd ~/lab6 <br>\n",
    "python3 tweetread.py\n",
    "</pre>\n",
    "\n",
    "Once you have this running, return to the notebook and keep going. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "## This command clears the enviroment. If you have any issues, try first to restart the kernel.\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the spark path in the folloiwng cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "findspark.init('/home/crystin/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# May cause deprecation warnings, safe to ignore, they aren't errors\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalTweetCount = 0 #stores the number of tweets\n",
    "totalCharacters = 0 #stores the total length of all tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Can only run this once. restart your kernel for any errors.\n",
    "#to do so click on Kernel, Resrart & Clear Output\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Note**: If you change the port number on tweetread.py, you need to update it here too.<br>\n",
    "- Both port numbers (here and tweetread.py) should match. <br>\n",
    "- You might need to restart the Kernel before continuing.<br>\n",
    "**Make sure your *tweetread.py* app is running before continue.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = ssc.socketTextStream(\"127.0.0.1\", 5558)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths = tweets.map(lambda tweet: len(tweet)) #get the length of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateCounts(rdd):\n",
    "    try:\n",
    "        count = rdd.count()\n",
    "        if(count>0):\n",
    "            global totalTweetCount\n",
    "            global totalCharacters\n",
    "            \n",
    "            totalTweetCount += count\n",
    "            totalCharacters += rdd.reduce(lambda len1,len2: len1+len2)\n",
    "            \n",
    "        if (totalTweetCount>0):\n",
    "            print('Total Tweets: ' + str(totalTweetCount) + '\\n' +\n",
    "                  'Total characters: ' + str(totalCharacters) + '\\n'\n",
    "                  'Average Length: ' + str(totalCharacters/totalTweetCount)+\n",
    "                 '\\n------------------------------\\n')\n",
    "        else:\n",
    "            print('nothing yet')\n",
    "        \n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths.foreachRDD(lambda rdd: updateCounts(rdd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now start the spark streaming context by running the next cell.**\n",
    "- You should see an updated output every 5 seconds\n",
    "\n",
    "*Once you are done, execute the stop command in the cell after.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nothing yet\n",
      "Total Tweets: 100\n",
      "Total characters: 18349\n",
      "Average Length: 183.49\n",
      "------------------------------\n",
      "\n",
      "Total Tweets: 176\n",
      "Total characters: 37171\n",
      "Average Length: 211.19886363636363\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.start()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tweets: 252\n",
      "Total characters: 57096\n",
      "Average Length: 226.57142857142858\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;background-color:#A74A54;color:#F1E6E7;padding:10px;\">\n",
    "    Questions\n",
    "</div>\n",
    "\n",
    "This code works fine if it is executed on a local machine. \n",
    "\n",
    "1. **Explain what will go wrong if it is executed on a cluster.**\n",
    "2. **How this issues can be solved?** *(No need to modify the code, just explain).*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If executed in a cluster it would be create a race condition. Each computer in the cluster may have different results, so then it would be a matter of which tweet came in a particular time. With a distributed setup, the computers will not be able to distinguish a proper ordering, to get a proper result for tweet count and character count."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "These issues can be solved by issuing a timestamp. The timestamp will allow the cluster to grab the tweet count and character count based off a unified time. \n",
    "\n",
    "Also by dispersing the data in chunks of 5 seconds will help grab the infomation in one call versus making calls to the entire cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"font-size:20px;background-color:#BE6D00;color:#F6EFE5;padding:10px;text-align:center;\">\n",
    "Submit this notebook with the output of the commands, and the answers for the previous two questions.\n",
    "</div>\n",
    "<hr style=\"border: 3px double navy;\" >\n",
    "<br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
